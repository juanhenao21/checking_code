{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAQ data extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_data_extract(ticker, type, year):\n",
    "    \"\"\"Extracts the data for every day in a year.\n",
    "\n",
    "    Extracts the trades and quotes (TAQ) data for a day from a CSV file with\n",
    "    the information of a whole year. The time range for each day is from 9:30\n",
    "    to 16:00, that means, the open market time.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param type: string with the type of the data to be extracted\n",
    "     (i.e. 'trades' or 'quotes').\n",
    "    :param year: string of the year to be analyzed (i.e. '2016').\n",
    "    :return: None -- The function extracts the data and does not return a\n",
    "     value.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        chunksize = 10 ** 7\n",
    "\n",
    "        init_date = f'01/01/{year}'\n",
    "        last_date = f'12/31/{year}'\n",
    "\n",
    "        # Use only the bussiness days\n",
    "        dt = pd.date_range(start=init_date, end=last_date, freq='B')\n",
    "        dt_df = dt.to_frame(index=False)\n",
    "        date_list = dt_df[0].astype(str).tolist()\n",
    "\n",
    "        # Load data\n",
    "        csv_file = f'data/{ticker}_{year}_NASDAQ_{type}.csv'\n",
    "\n",
    "        df_type = {'quotes': {\n",
    "                        'Date': 'str',\n",
    "                        'Time': 'int',\n",
    "                        'Bid': 'int',\n",
    "                        'Ask': 'int',\n",
    "                        'Vol_Bid': 'int',\n",
    "                        'Vol_Ask': 'int',\n",
    "                        'Mode': 'int',\n",
    "                        'Cond': 'str',\n",
    "                    },\n",
    "                   'trades': {\n",
    "                        'Date': 'str',\n",
    "                        'Time': 'int',\n",
    "                        'Ask': 'int',\n",
    "                        'Vol_Ask': 'int',\n",
    "                        'Mode': 'int',\n",
    "                        'Corr': 'int',\n",
    "                        'Cond': 'str',\n",
    "                    }}\n",
    "\n",
    "        col_names = {'quotes': ['Date', 'Time', 'Bid', 'Ask', 'Vol_Bid',\n",
    "                                'Vol_Ask', 'Mode', 'Cond'],\n",
    "                     'trades': ['Date', 'Time', 'Ask', 'Vol_Ask', 'Mode',\n",
    "                                'Corr', 'Cond']}\n",
    "\n",
    "        # Save data\n",
    "        if (not os.path.isdir(f'hdf5_dayly_data_{year}/')):\n",
    "\n",
    "            try:\n",
    "                os.mkdir(f'hdf5_dayly_data_{year}/')\n",
    "                print('Folder to save data created')\n",
    "\n",
    "            except FileExistsError:\n",
    "                print('Folder exists. The folder was not created')\n",
    "\n",
    "        for chunk in pd.read_csv(csv_file, chunksize=chunksize, sep='\\s+',\n",
    "                                 names=col_names[type], dtype=df_type[type],\n",
    "                                 na_filter=False, low_memory=False):\n",
    "\n",
    "            chunk['Date'] = pd.to_datetime(chunk['Date'], format='%Y-%m-%d')\n",
    "            chunk.set_index('Date', inplace=True)\n",
    "            if (type == 'quotes'):\n",
    "                chunk.drop(['Mode', 'Cond'], axis=1, inplace=True)\n",
    "            else:\n",
    "                chunk.drop(['Mode', 'Corr', 'Cond'], axis=1, inplace=True)\n",
    "\n",
    "            for date in date_list:\n",
    "                day = chunk.index.isin([date])\n",
    "                df = chunk.loc[day & (chunk['Time'] >= 34200)\n",
    "                               & (chunk['Time'] < 57600)]\n",
    "\n",
    "                if not df.empty:\n",
    "                    df.to_hdf(f''.join(('hdf5_dayly_data_'\n",
    "                              + f'{year}/taq_{ticker}_{type}_{date}.h5')\n",
    "                              .split()), key=type,\n",
    "                              format='table', append=True)\n",
    "\n",
    "        print('Data Saved')\n",
    "        print()\n",
    "\n",
    "        return None\n",
    "\n",
    "    except AssertionError:\n",
    "        print('No data')\n",
    "        print()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following blocks measure the time used to extract the data. As the function append new information every time the function is runned, I delete the files in every run of the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_i = 'AAPL'\n",
    "ticker_j = 'MSFT'\n",
    "type_q = 'quotes'\n",
    "type_t = 'trades'\n",
    "year = '2008'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "12min 56s ± 1min 26s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "taq_data_extract(ticker_i, type_q, year)\n",
    "os.system('rm hdf5_dayly_data_2008/*.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "2min 13s ± 2.18 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "taq_data_extract(ticker_i, type_t, year)\n",
    "os.system('rm hdf5_dayly_data_2008/*.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "16min 56s ± 3min per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "taq_data_extract(ticker_j, type_q, year)\n",
    "os.system('rm hdf5_dayly_data_2008/*.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "Data Saved\n",
      "\n",
      "2min 1s ± 2.4 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "taq_data_extract(ticker_j, type_t, year)\n",
    "os.system('rm hdf5_dayly_data_2008/*.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following block extract the data that will be computed by the other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AAPL', 'TAQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.87 µs\n",
      "Extracting dayly data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'taq_data_analysis_article_reproduction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ee374404a19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting dayly data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     pool.starmap(taq_data_analysis_article_reproduction.taq_data_extract,\n\u001b[0m\u001b[1;32m      5\u001b[0m                  product(tickers, ['quotes'], [year]))\n\u001b[1;32m      6\u001b[0m     pool.starmap(taq_data_analysis_article_reproduction.taq_data_extract,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taq_data_analysis_article_reproduction' is not defined"
     ]
    }
   ],
   "source": [
    "%time\n",
    "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "    print('Extracting dayly data')\n",
    "    pool.starmap(taq_data_analysis_article_reproduction.taq_data_extract,\n",
    "                 product(tickers, ['quotes'], [year]))\n",
    "    pool.starmap(taq_data_analysis_article_reproduction.taq_data_extract,\n",
    "                 product(tickers, ['trades'], [year]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
