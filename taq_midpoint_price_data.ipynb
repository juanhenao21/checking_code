{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAQ midpoint price data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la implementacion del midpoint price, divido la tarea en dos partes. Primero obtengo los resultados para todos los eventos en un dia y luego con otra funcion los calculo para todos los segundos en el dia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### midpoint price data por evento por dia\n",
    "\n",
    "Esta funcion no tiene problema en cuanto al tiempo de ejecucion. Las operaciones que realiza son muy basicas. Sin embargo, mi implementacion anterior usando solo `numpy` se demoraba 0,020s por dia y ahora se demora 0.1s por dia utilizando `pandas`.\n",
    "\n",
    "La implementacion con `numpy` la voy a nombrar `taq_midpoint_event_data_numpy` y la implementacion con `pandas` la voy a nombrar `taq_midpoint_event_data_pandas`.\n",
    "\n",
    "En este caso no entiendo por que con `pandas` es mas lento. La unica diferencia que hay es que la funcion de `numpy` lee un archivo `pickle` con una tupla con arrays mientras que la funcion `pandas` lee un archivo `hdf5` con un `DataFrame` de `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_midpoint_event_data_numpy(ticker, year, month, day):\n",
    "    \"\"\"Computes the midpoint price of every event.\n",
    "\n",
    "    Using the dayly TAQ data computes the midpoint price of every event in a\n",
    "    day.\n",
    "    For further calculations, the function returns the values for the time\n",
    "    range from 9h40 to 15h50.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param year: string of the year to be analized (i.e '2008').\n",
    "    :param month: string of the month to be analized (i.e '07').\n",
    "    :param day: string of the day to be analized (i.e '07').\n",
    "    :return: tuple -- The function returns a tuple with numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data\n",
    "    # TAQ data gives directly the quotes data in every second that there is\n",
    "    # a change in the quotes\n",
    "    time_q_, bid_q_, ask_q_, _, _ = pickle.load(open(\n",
    "        f'pickle_dayly_data_{year}/TAQ_{ticker}_quotes_{year}{month}{day}.pickle', 'rb'))\n",
    "\n",
    "    # Some files are corrupted, so there are some zero values that\n",
    "    # does not have sense\n",
    "    condition_1 = ask_q_ != 0.\n",
    "    time_q = time_q_[condition_1]\n",
    "    bid_q = bid_q_[condition_1]\n",
    "    ask_q = ask_q_[condition_1]\n",
    "\n",
    "    assert len(bid_q) == len(ask_q)\n",
    "\n",
    "    midpoint = (bid_q + ask_q) / 2\n",
    "    spread = ask_q - bid_q\n",
    "\n",
    "    return (time_q, bid_q, ask_q, midpoint, spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_midpoint_event_data_pandas(ticker, date):\n",
    "    \"\"\"Computes the midpoint price of every event.\n",
    "\n",
    "    Using the dayly TAQ data computes the midpoint price of every event in a\n",
    "    day.\n",
    "    For further calculations, the function returns the values for the time\n",
    "    range from 9h40 to 15h50.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param year: string of the year to be analized (i.e '2008').\n",
    "    :param month: string of the month to be analized (i.e '07').\n",
    "    :param day: string of the day to be analized (i.e '07').\n",
    "    :return: tuple -- The function returns a tuple with numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    date_sep = date.split('-')\n",
    "    year = date_sep[0]\n",
    "    month = date_sep[1]\n",
    "    day = date_sep[2]\n",
    "\n",
    "    # Load data\n",
    "    # TAQ data gives directly the quotes data in every second that there is\n",
    "    # a change in the quotes\n",
    "    data_quotes_event = pd.read_hdf(\n",
    "        f'hdf5_dayly_data_{year}/taq_{ticker}_quotes_{date}.h5')\n",
    "\n",
    "    # Some files are corrupted, so there are some zero values that\n",
    "    # does not have sense\n",
    "    data_quotes_event = data_quotes_event[data_quotes_event['Ask'] != 0]\n",
    "\n",
    "    data_quotes_event['Midpoint'] = (data_quotes_event['Bid']\n",
    "                                     + data_quotes_event['Ask']) / 2\n",
    "    data_quotes_event['Spread'] = data_quotes_event['Ask'] \\\n",
    "        - data_quotes_event['Bid']\n",
    "\n",
    "    return data_quotes_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "year = '2008'\n",
    "month = '01'\n",
    "day = '02'\n",
    "date = f'{year}-{month}-{day}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.8 ms ± 693 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "taq_midpoint_event_data_numpy(ticker, year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.6 ms ± 4.75 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "taq_midpoint_event_data_pandas(ticker, date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### midpoint price data por segundo por dia\n",
    "\n",
    "Los datos obtenidos por la anterior funcion, dan los midpoint prices para cada evento. La idea con la siguiente funcion es obtener un punto valor de midpoint price por segundo en cada dia. Dado que no todos los segundos tienen necesariamente un valor de midpoint price, se da a los segundo sin precio el valor del segundo anterior.\n",
    "\n",
    "La implementacion con `numpy` la voy a nombrar `taq_midpoint_time_data_numpy` y la implementacion con `pandas` la voy a nombrar `taq_midpoint_time_data_pandas`.\n",
    "\n",
    "En este caso, la funcion se demora mucho en el paso en el que tiene que hacer la busqueda de los valores de cada segundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_midpoint_time_data_numpy(ticker, date):\n",
    "    \"\"\"Computes the midpoint price of every second.\n",
    "\n",
    "    Using the taq_midpoint_event_data function computes the midpoint price of\n",
    "    every second. To fill the time spaces when nothing happens I replicate the\n",
    "    last value calculated until a change in the price happens.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param date: string with the date of the data to be extracted\n",
    "     (i.e. '2008-01-02').\n",
    "    :return: numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    date_sep = date.split('-')\n",
    "\n",
    "    year = date_sep[0]\n",
    "    month = date_sep[1]\n",
    "    day = date_sep[2]\n",
    "\n",
    "    function_name = taq_midpoint_time_data_numpy.__name__\n",
    "\n",
    "    try:\n",
    "        # Calculate the values of the midpoint price for all the events\n",
    "        (time_q, bid_q, ask_q,\n",
    "         midpoint, spread) = taq_midpoint_event_data_numpy(ticker, year, month, day)\n",
    "\n",
    "        # 34800 s = 9h40 - 57000 s = 15h50\n",
    "        # Reproducing S. Wang values. In her results the time interval for the\n",
    "        # midpoint is [34800, 56999]\n",
    "        full_time = np.array(range(34800, 57000))\n",
    "\n",
    "        # As there can be several values for the same second, we use the\n",
    "        # last value of each second in the full time array as it behaves\n",
    "        # quiet equal as the original input\n",
    "\n",
    "        midpoint_last_val = 0. * full_time\n",
    "        midpoint_last_val[-1] = midpoint[0]\n",
    "\n",
    "        ask_last_val = 0. * full_time\n",
    "        ask_last_val[-1] = ask_q[0]\n",
    "\n",
    "        bid_last_val = 0. * full_time\n",
    "        bid_last_val[-1] = bid_q[0]\n",
    "\n",
    "        spread_last_val = 0. * full_time\n",
    "        spread_last_val[-1] = spread[0]\n",
    "\n",
    "        for t_idx, t_val in enumerate(full_time):\n",
    "\n",
    "            condition = time_q == t_val\n",
    "\n",
    "            if (np.sum(condition)):\n",
    "\n",
    "                midpoint_last_val[t_idx] = midpoint[condition][-1]\n",
    "                ask_last_val[t_idx] = ask_q[condition][-1]\n",
    "                bid_last_val[t_idx] = bid_q[condition][-1]\n",
    "                spread_last_val[t_idx] = spread[condition][-1]\n",
    "\n",
    "            else:\n",
    "\n",
    "                midpoint_last_val[t_idx] = midpoint_last_val[t_idx - 1]\n",
    "                ask_last_val[t_idx] = ask_last_val[t_idx - 1]\n",
    "                bid_last_val[t_idx] = bid_last_val[t_idx - 1]\n",
    "                spread_last_val[t_idx] = spread_last_val[t_idx - 1]\n",
    "\n",
    "        # There should not be 0 values in the midpoint array\n",
    "        assert not np.sum(midpoint_last_val == 0)\n",
    "\n",
    "        return midpoint_last_val\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "            print('No data')\n",
    "            print(e)\n",
    "            print()\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_midpoint_time_data_pandas(ticker, date):\n",
    "    \"\"\"Computes the midpoint price of every second.\n",
    "\n",
    "    Using the taq_midpoint_event_data function computes the midpoint price of\n",
    "    every second. To fill the time spaces when nothing happens I replicate the\n",
    "    last value calculated until a change in the price happens.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param date: string with the date of the data to be extracted\n",
    "     (i.e. '2008-01-02').\n",
    "    :return: numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    date_sep = date.split('-')\n",
    "\n",
    "    year = date_sep[0]\n",
    "    month = date_sep[1]\n",
    "    day = date_sep[2]\n",
    "\n",
    "    function_name = taq_midpoint_time_data_pandas.__name__\n",
    "\n",
    "    try:\n",
    "        # Calculate the values of the midpoint price for all the events\n",
    "        data_quotes_event = taq_midpoint_event_data_pandas(ticker, date)\n",
    "\n",
    "        # 34800 s = 9h40 - 57000 s = 15h50\n",
    "        # Reproducing S. Wang values. In her results the time interval for the\n",
    "        # midpoint is [34800, 56999]\n",
    "        full_time = np.array(range(34800, 57000))\n",
    "\n",
    "        # As there can be several values for the same second, we use the\n",
    "        # last value of each second in the full time array as it behaves\n",
    "        # quiet equal as the original input\n",
    "        set_data_time = np.array(list(set(data_quotes_event['Time'])))\n",
    "        list_data_time = [0] * len(full_time)\n",
    "\n",
    "        for t_idx, t_val in enumerate(full_time):\n",
    "            \n",
    "            condition = data_quotes_event['Time'] == t_val\n",
    "            \n",
    "            if (np.sum(condition)):\n",
    "\n",
    "                data_dict = {'Time': data_quotes_event[condition].iloc[-1]['Time'],\n",
    "                             'Midpoint': data_quotes_event[condition].iloc[-1]['Midpoint']}\n",
    "\n",
    "                list_data_time[t_idx] = data_dict\n",
    "\n",
    "        data_quotes_time = pd.DataFrame(list_data_time, columns=['Time', 'Midpoint'])\n",
    "        data_quotes_time['Time'] = full_time        \n",
    "        \n",
    "        for m_idx, m_val in enumerate(data_quotes_time['Midpoint']):\n",
    "            if (not m_val):\n",
    "                data_quotes_time['Midpoint'][m_idx] = data_quotes_time['Midpoint'][m_idx - 1]\n",
    "\n",
    "        return data_quotes_time\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print('No data')\n",
    "        print(e)\n",
    "        print()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.8 s ± 418 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "taq_midpoint_time_data_numpy(ticker, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f5420ac9e09b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%%timeit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtaq_midpoint_time_data_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-5f165650d3c4>\u001b[0m in \u001b[0;36mtaq_midpoint_time_data_pandas\u001b[0;34m(ticker, date)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mlist_data_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mdata_quotes_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_data_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Midpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mdata_quotes_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/checking_code/env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/checking_code/env/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         return _list_of_dict_to_arrays(\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         )\n\u001b[1;32m    469\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/checking_code/env/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_of_dict_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;31m# assure that they are of the base dict class and not of derived\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;31m# classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0md\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdicts_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/checking_code/env/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;31m# assure that they are of the base dict class and not of derived\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;31m# classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0md\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdicts_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "taq_midpoint_time_data_pandas(ticker, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_midpoint_time_data_pandas_v1(ticker, date):\n",
    "    \"\"\"Computes the midpoint price of every second.\n",
    "\n",
    "    Using the taq_midpoint_event_data function computes the midpoint price of\n",
    "    every second. To fill the time spaces when nothing happens I replicate the\n",
    "    last value calculated until a change in the price happens.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param date: string with the date of the data to be extracted\n",
    "     (i.e. '2008-01-02').\n",
    "    :return: numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    date_sep = date.split('-')\n",
    "\n",
    "    year = date_sep[0]\n",
    "    month = date_sep[1]\n",
    "    day = date_sep[2]\n",
    "\n",
    "    function_name = taq_midpoint_time_data.__name__\n",
    "\n",
    "    try:\n",
    "        # Calculate the values of the midpoint price for all the events\n",
    "        data_quotes_event = taq_midpoint_event_data_pandas(ticker, date)\n",
    "\n",
    "        # 34800 s = 9h40 - 57000 s = 15h50\n",
    "        # Reproducing S. Wang values. In her results the time interval for the\n",
    "        # midpoint is [34800, 56999]\n",
    "        full_time = np.array(range(34800, 57000))\n",
    "\n",
    "        # As there can be several values for the same second, we use the\n",
    "        # last value of each second in the full time array as it behaves\n",
    "        # quiet equal as the original input\n",
    "        set_data_time = np.array(list(set(data_quotes_event['Time'])))\n",
    "        list_data_time = [0] * len(full_time)\n",
    "\n",
    "        for t_idx, t_val in enumerate(full_time):\n",
    "            condition = data_quotes_event['Time'] == t_val\n",
    "            if (np.sum(condition)):\n",
    "                \n",
    "                data_dict = {'Time': data_quotes_event[condition].iloc[-1]['Time'],\n",
    "                             'Midpoint': data_quotes_event[condition].iloc[-1]['Midpoint']}\n",
    "\n",
    "                list_data_time[t_idx] = data_dict\n",
    "\n",
    "            else:\n",
    "\n",
    "                data_dict = {'Time': list_data_time[t_idx - 1]['Time'],\n",
    "                             'Midpoint': list_data_time[t_idx - 1]['Midpoint']}\n",
    "\n",
    "                list_data_time[t_idx] = data_dict\n",
    "\n",
    "        data_quotes_time = pd.DataFrame(list_data_time, columns=['Time', 'Midpoint'])\n",
    "\n",
    "        # The lengths of the time and the dataframe have to be the same\n",
    "        assert len(full_time) == len(data_quotes_time['Time'])\n",
    "\n",
    "        data_quotes_time['Time'] = full_time\n",
    "\n",
    "        return data_quotes_time\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print('No data')\n",
    "        print(e)\n",
    "        print()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.1 s ± 394 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "taq_midpoint_time_data_pandas_v1(ticker, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_midpoint_time_data_pandas_v3(ticker, date):\n",
    "    \"\"\"Computes the midpoint price of every second.\n",
    "\n",
    "    Using the taq_midpoint_event_data function computes the midpoint price of\n",
    "    every second. To fill the time spaces when nothing happens I replicate the\n",
    "    last value calculated until a change in the price happens.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param date: string with the date of the data to be extracted\n",
    "     (i.e. '2008-01-02').\n",
    "    :return: numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    date_sep = date.split('-')\n",
    "\n",
    "    year = date_sep[0]\n",
    "    month = date_sep[1]\n",
    "    day = date_sep[2]\n",
    "\n",
    "    function_name = taq_midpoint_time_data.__name__\n",
    "\n",
    "    try:\n",
    "        # Calculate the values of the midpoint price for all the events\n",
    "        data_quotes_event = taq_midpoint_event_data_pandas(ticker, date)\n",
    "\n",
    "        # 34800 s = 9h40 - 57000 s = 15h50\n",
    "        # Reproducing S. Wang values. In her results the time interval for the\n",
    "        # midpoint is [34800, 56999]\n",
    "        full_time = np.array(range(34800, 57000))\n",
    "\n",
    "        # As there can be several values for the same second, we use the\n",
    "        # last value of each second in the full time array as it behaves\n",
    "        # quiet equal as the original input\n",
    "        set_data_time = np.array(list(set(data_quotes_event['Time'])))\n",
    "        list_data_time = [0] * len(full_time)\n",
    "\n",
    "        for t_idx, t_val in enumerate(full_time):\n",
    "            condition = data_quotes_event['Time'] == t_val\n",
    "            if (np.sum(condition)):\n",
    "                \n",
    "                # data_dict = {'Time': data_quotes_event[condition].iloc[-1]['Time'],\n",
    "                #              'Midpoint': data_quotes_event[condition].iloc[-1]['Midpoint']}\n",
    "\n",
    "                # list_data_time[t_idx] = data_dict\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "\n",
    "                # data_dict = {'Time': list_data_time[t_idx - 1]['Time'],\n",
    "                #              'Midpoint': list_data_time[t_idx - 1]['Midpoint']}\n",
    "\n",
    "                # list_data_time[t_idx] = data_dict\n",
    "                pass\n",
    "\n",
    "        # data_quotes_time = pd.DataFrame(list_data_time, columns=['Time', 'Midpoint'])\n",
    "\n",
    "        # The lengths of the time and the dataframe have to be the same\n",
    "        # assert len(full_time) == len(data_quotes_time['Time'])\n",
    "\n",
    "        # data_quotes_time['Time'] = full_time\n",
    "\n",
    "        # return data_quotes_time\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print('No data')\n",
    "        print(e)\n",
    "        print()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.5 s ± 497 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "taq_midpoint_time_data_pandas_v3(ticker, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
