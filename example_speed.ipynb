{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "__tau__ = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_data_extract(ticker, type, year):\n",
    "    \"\"\"Extracts the data for every day in a year.\n",
    "\n",
    "    Extracts the trades and quotes (TAQ) data for a day from a CSV file with\n",
    "    the information of a whole year. The time range for each day is from 9:30\n",
    "    to 16:00, that means, the open market time.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param type: string with the type of the data to be extracted\n",
    "     (i.e. 'trades' or 'quotes').\n",
    "    :param year: string of the year to be analyzed (i.e. '2016').\n",
    "    :return: None -- The function extracts the data and does not return a\n",
    "     value.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        chunksize = 10 ** 7\n",
    "\n",
    "        date_list = taq_data_tools_article_reproduction \\\n",
    "            .taq_bussiness_days(year)\n",
    "\n",
    "        # Load data\n",
    "        csv_file = f'{ticker}_{year}_NASDAQ_{type}.csv'\n",
    "\n",
    "        df_type = {'quotes': {\n",
    "                        'Date': 'str',\n",
    "                        'Time': 'int',\n",
    "                        'Bid': 'int',\n",
    "                        'Ask': 'int',\n",
    "                        'Vol_Bid': 'int',\n",
    "                        'Vol_Ask': 'int',\n",
    "                        'Mode': 'int',\n",
    "                        'Cond': 'str',\n",
    "                    },\n",
    "                   'trades': {\n",
    "                        'Date': 'str',\n",
    "                        'Time': 'int',\n",
    "                        'Ask': 'int',\n",
    "                        'Vol_Ask': 'int',\n",
    "                        'Mode': 'int',\n",
    "                        'Corr': 'int',\n",
    "                        'Cond': 'str',\n",
    "                    }}\n",
    "\n",
    "        col_names = {'quotes': ['Date', 'Time', 'Bid', 'Ask', 'Vol_Bid',\n",
    "                                'Vol_Ask', 'Mode', 'Cond'],\n",
    "                     'trades': ['Date', 'Time', 'Ask', 'Vol_Ask', 'Mode',\n",
    "                                'Corr', 'Cond']}\n",
    "\n",
    "        # Save data\n",
    "        if (not os.path.isdir(f'hdf5_dayly_data_{year}/')):\n",
    "\n",
    "            try:\n",
    "                os.mkdir(f'hdf5_dayly_data_{year}/')\n",
    "                print('Folder to save data created')\n",
    "\n",
    "            except FileExistsError:\n",
    "                print('Folder exists. The folder was not created')\n",
    "\n",
    "        for chunk in pd.read_csv(csv_file, chunksize=chunksize, sep='\\s+',\n",
    "                                 names=col_names[type], dtype=df_type[type],\n",
    "                                 na_filter=False, low_memory=False):\n",
    "\n",
    "            chunk['Date'] = pd.to_datetime(chunk['Date'], format='%Y-%m-%d')\n",
    "            chunk.set_index('Date', inplace=True)\n",
    "            if (type == 'quotes'):\n",
    "                chunk.drop(['Mode', 'Cond'], axis=1, inplace=True)\n",
    "            else:\n",
    "                chunk.drop(['Mode', 'Corr', 'Cond'], axis=1, inplace=True)\n",
    "\n",
    "            for date in date_list:\n",
    "                day = chunk.index.isin([date])\n",
    "                df = chunk.loc[day & (chunk['Time'] >= 34200)\n",
    "                               & (chunk['Time'] < 57600)]\n",
    "\n",
    "                if not df.empty:\n",
    "                    df.to_hdf(f''.join(('hdf5_dayly_data_'\n",
    "                              + f'{year}/taq_{ticker}_{type}_{date}.h5')\n",
    "                              .split()), key=type,\n",
    "                              format='table', append=True)\n",
    "\n",
    "        print('Data Saved')\n",
    "        print()\n",
    "\n",
    "        return None\n",
    "\n",
    "    except AssertionError:\n",
    "        print('No data')\n",
    "        print()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_midpoint_event_data(ticker, date):\n",
    "    \"\"\"Computes the midpoint price of every event.\n",
    "\n",
    "    Using the dayly TAQ data computes the midpoint price of every event in a\n",
    "    day.\n",
    "    For further calculations, the function returns the values for the time\n",
    "    range from 9h40 to 15h50.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param year: string of the year to be analized (i.e '2008').\n",
    "    :param month: string of the month to be analized (i.e '07').\n",
    "    :param day: string of the day to be analized (i.e '07').\n",
    "    :return: tuple -- The function returns a tuple with numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    date_sep = date.split('-')\n",
    "    year = date_sep[0]\n",
    "    month = date_sep[1]\n",
    "    day = date_sep[2]\n",
    "\n",
    "    # Load data\n",
    "    # TAQ data gives directly the quotes data in every second that there is\n",
    "    # a change in the quotes\n",
    "    data_quotes_event = pd.read_hdf(\n",
    "        f'hdf5_dayly_data_{year}/taq_{ticker}_quotes_{date}.h5')\n",
    "\n",
    "    # Some files are corrupted, so there are some zero values that\n",
    "    # does not have sense\n",
    "    data_quotes_event = data_quotes_event[data_quotes_event['Ask'] != 0]\n",
    "\n",
    "    data_quotes_event['Midpoint'] = (data_quotes_event['Bid']\n",
    "                                     + data_quotes_event['Ask']) / 2\n",
    "    data_quotes_event['Spread'] = data_quotes_event['Ask'] \\\n",
    "        - data_quotes_event['Bid']\n",
    "\n",
    "    return data_quotes_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_midpoint_time_data(ticker, date):\n",
    "    \"\"\"Computes the midpoint price of every second.\n",
    "\n",
    "    Using the taq_midpoint_event_data function computes the midpoint price of\n",
    "    every second. To fill the time spaces when nothing happens I replicate the\n",
    "    last value calculated until a change in the price happens.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param date: string with the date of the data to be extracted\n",
    "     (i.e. '2008-01-02').\n",
    "    :return: numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    date_sep = date.split('-')\n",
    "\n",
    "    year = date_sep[0]\n",
    "    month = date_sep[1]\n",
    "    day = date_sep[2]\n",
    "\n",
    "    function_name = taq_midpoint_time_data.__name__\n",
    "\n",
    "    try:\n",
    "        # Calculate the values of the midpoint price for all the events\n",
    "        data_quotes_event = taq_midpoint_event_data(ticker, date)\n",
    "\n",
    "        # 34800 s = 9h40 - 57000 s = 15h50\n",
    "        # Reproducing S. Wang values. In her results the time interval for the\n",
    "        # midpoint is [34800, 56999]\n",
    "        full_time = np.array(range(34800, 57000))\n",
    "\n",
    "        # As there can be several values for the same second, we use the\n",
    "        # last value of each second in the full time array as it behaves\n",
    "        # quiet equal as the original input\n",
    "        set_data_time = np.array(list(set(data_quotes_event['Time'])))\n",
    "        list_data_time = [0] * len(full_time)\n",
    "\n",
    "        for t_idx, t_val in enumerate(full_time):\n",
    "            if (np.sum(t_val == set_data_time)):\n",
    "\n",
    "                condition = data_quotes_event['Time'] == t_val\n",
    "                data_dict = {'Time': data_quotes_event[condition].ix[-1]['Time'],\n",
    "                             'Midpoint': data_quotes_event[condition].ix[-1]['Midpoint']}\n",
    "\n",
    "                list_data_time[t_idx] = data_dict\n",
    "\n",
    "            else:\n",
    "\n",
    "                data_dict = {'Time': list_data_time[t_idx - 1]['Time'],\n",
    "                             'Midpoint': list_data_time[t_idx - 1]['Midpoint']}\n",
    "\n",
    "                list_data_time[t_idx] = data_dict\n",
    "\n",
    "        data_quotes_time = pd.DataFrame(list_data_time, columns=['Time', 'Midpoint'])\n",
    "\n",
    "        # The lengths of the time and the dataframe have to be the same\n",
    "        assert len(full_time) == len(data_quotes_time['Time'])\n",
    "\n",
    "        data_quotes_time['Time'] = full_time\n",
    "\n",
    "        # Saving data\n",
    "\n",
    "        if (not os.path.isdir(f'{function_name}/')):\n",
    "\n",
    "            try:\n",
    "                os.mkdir(f'{function_name}/')\n",
    "                print('Folder to save data created')\n",
    "\n",
    "            except FileExistsError:\n",
    "                print('Folder exists. The folder was not created')\n",
    "\n",
    "        data_quotes_time.astype(str).to_hdf(''.join((f'{function_name}/'\n",
    "                                + f'{function_name}_quotes_{year}{month}{day}'\n",
    "                                + f'_{ticker}.h5').split()),\n",
    "                                key='data_quotes_time', mode='w', format='table')\n",
    "\n",
    "        print('Data saved')\n",
    "        print()\n",
    "\n",
    "        return data_quotes_time\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print('No data')\n",
    "        print(e)\n",
    "        print()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_trade_signs_event_data(ticker, year, month, day):\n",
    "    \"\"\"Computes the trade signs of every event.\n",
    "\n",
    "    Using the dayly TAQ data computes the trade signs of every event in a day.\n",
    "    The trade signs are computed using the equation (1) of the\n",
    "    `paper <https://arxiv.org/pdf/1603.01580.pdf>`_.\n",
    "    As the trades signs are not directly given by the TAQ data, they must be\n",
    "    infered by the trades prices.\n",
    "    For further calculations, the function returns the values for the time\n",
    "    range from 9h40 to 15h50.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "        (i.e. 'AAPL').\n",
    "    :param year: string of the year to be analized (i.e '2016').\n",
    "    :param month: string of the month to be analized (i.e '07').\n",
    "    :param day: string of the day to be analized (i.e '07').\n",
    "    :return: tuple -- The function returns a tuple with numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    function_name = taq_trade_signs_event_data.__name__\n",
    "    taq_data_tools_article_reproduction \\\n",
    "        .taq_function_header_print_data(function_name, ticker, ticker, year,\n",
    "                                        month, day)\n",
    "\n",
    "    # Load data\n",
    "    time_t, ask_t, _ = pickle.load(open(\n",
    "        '../../taq_data/pickle_dayly_data_{1}/TAQ_{0}_trades_{1}{2}{3}.pickle'\n",
    "        .format(ticker, year, month, day), 'rb'))\n",
    "\n",
    "    # All the trades must have a price different to zero\n",
    "    assert not np.sum(ask_t == 0)\n",
    "\n",
    "    # Trades identified using equation (1)\n",
    "    identified_trades = np.zeros(len(time_t))\n",
    "    identified_trades[-1] = 1\n",
    "\n",
    "    # Implementation of equation (1). Sign of the price change between\n",
    "    # consecutive trades\n",
    "\n",
    "    for t_idx in range(len(time_t)):\n",
    "\n",
    "        diff = ask_t[t_idx] - ask_t[t_idx - 1]\n",
    "\n",
    "        if (diff):\n",
    "            identified_trades[t_idx] = np.sign(diff)\n",
    "\n",
    "        else:\n",
    "            identified_trades[t_idx] = identified_trades[t_idx - 1]\n",
    "\n",
    "    # All the identified trades must be different to zero\n",
    "    assert not np.sum(identified_trades == 0)\n",
    "\n",
    "    return (time_t, ask_t, identified_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_trade_signs_time_data(ticker, date):\n",
    "    \"\"\"Computes the trade signs of every second.\n",
    "\n",
    "    Using the taq_trade_signs_event_data function computes the trade signs of\n",
    "    every second.\n",
    "    The trade signs are computed using the equation (2) of the\n",
    "    `paper <https://arxiv.org/pdf/1603.01580.pdf>`_.\n",
    "    As the trades signs are not directly given by the TAQ data, they must be\n",
    "    infered by the trades prices.\n",
    "    For further calculations, the function returns the values for the time\n",
    "    range from 9h40 to 15h50.\n",
    "    To fill the time spaces when nothing happens I added zeros indicating that\n",
    "    there were neither a buy nor a sell.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param date: string with the date of the data to be extracted\n",
    "     (i.e. '2008-01-02').\n",
    "    :return: tuple -- The function returns a tuple with numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    date_sep = date.split('-')\n",
    "\n",
    "    year = date_sep[0]\n",
    "    month = date_sep[1]\n",
    "    day = date_sep[2]\n",
    "\n",
    "    function_name = taq_trade_signs_time_data.__name__\n",
    "    taq_data_tools_article_reproduction \\\n",
    "        .taq_function_header_print_data(function_name, ticker, ticker, year,\n",
    "                                        month, day)\n",
    "\n",
    "    try:\n",
    "        # Calculate the values of the trade signs for all the events\n",
    "        (time_t, ask_t,\n",
    "         identified_trades) = taq_trade_signs_event_data(ticker, year, month,\n",
    "                                                         day)\n",
    "\n",
    "        # Reproducing S. Wang values. In her results the time interval for the\n",
    "        # trade signs is [34801, 57000]\n",
    "        full_time = np.array(range(34801, 57001))\n",
    "\n",
    "        trade_signs = 0. * full_time\n",
    "        price_signs = 0. * full_time\n",
    "\n",
    "        # Implementation of equation (2). Trade sign in each second\n",
    "        for t_idx, t_val in enumerate(full_time):\n",
    "\n",
    "            condition = (time_t >= t_val) * (time_t < t_val + 1)\n",
    "            # Empirical\n",
    "            trades_same_t_exp = identified_trades[condition]\n",
    "            sign_exp = int(np.sign(np.sum(trades_same_t_exp)))\n",
    "            trade_signs[t_idx] = sign_exp\n",
    "            try:\n",
    "                price_signs[t_idx] = ask_t[condition][-1]\n",
    "            except IndexError as e:\n",
    "                full_time[t_idx] = 0\n",
    "\n",
    "        # Saving data\n",
    "        taq_data_tools_article_reproduction \\\n",
    "            .taq_save_data(function_name,\n",
    "                           (full_time, price_signs, trade_signs),\n",
    "                           ticker, ticker, year, month, day)\n",
    "\n",
    "        return (full_time, price_signs, trade_signs)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print('No data')\n",
    "        print(e)\n",
    "        print()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_self_response_day_data(ticker, date):\n",
    "    \"\"\"Computes the self response of a day.\n",
    "\n",
    "    Using the midpoint price and trade signs of a ticker computes the self-\n",
    "    response during different time lags (:math:`\\tau`) for a day.\n",
    "\n",
    "    :param ticker: string of the abbreviation of the stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param date: string with the date of the data to be extracted\n",
    "     (i.e. '2008-01-02').\n",
    "    :return: tuple -- The function returns a tuple with numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    date_sep = date.split('-')\n",
    "\n",
    "    year = date_sep[0]\n",
    "    month = date_sep[1]\n",
    "    day = date_sep[2]\n",
    "\n",
    "    function_name = taq_self_response_day_data.__name__\n",
    "    taq_data_tools_article_reproduction \\\n",
    "        .taq_function_header_print_data(function_name, ticker, ticker, year,\n",
    "                                        month, day)\n",
    "\n",
    "    try:\n",
    "        # Load data\n",
    "        midpoint = pickle.load(open(''.join((\n",
    "                '../../taq_data/article_reproduction_data_{1}/taq_midpoint'\n",
    "                + '_time_data/taq_midpoint_time_data_midpoint_{1}'\n",
    "                + '{2}{3}_{0}.pickle').split())\n",
    "                .format(ticker, year, month, day), 'rb'))\n",
    "        _, _, trade_sign = pickle.load(open(\"\".join((\n",
    "                '../../taq_data/article_reproduction_data_{1}/taq_trade_signs'\n",
    "                + '_time_data/taq_trade_signs_time_data_{1}{2}{3}_'\n",
    "                + '{0}.pickle').split())\n",
    "                .format(ticker, year, month, day), 'rb'))\n",
    "\n",
    "        assert len(midpoint) == len(trade_sign)\n",
    "\n",
    "        # Array of the average of each tau. 10^3 s used by Wang\n",
    "        self_response_tau = np.zeros(__tau__)\n",
    "        num = np.zeros(__tau__)\n",
    "\n",
    "        # Calculating the midpoint price return and the self response function\n",
    "\n",
    "        # Depending on the tau value\n",
    "        for tau_idx in range(__tau__):\n",
    "\n",
    "            trade_sign_tau = trade_sign[:-tau_idx - 1]\n",
    "            trade_sign_no_0_len = len(trade_sign_tau[trade_sign_tau != 0])\n",
    "            num[tau_idx] = trade_sign_no_0_len\n",
    "            # Obtain the midpoint price return. Displace the numerator tau\n",
    "            # values to the right and compute the return\n",
    "\n",
    "            # midpoint price returns\n",
    "\n",
    "            log_return_sec = (midpoint[tau_idx + 1:]\n",
    "                              - midpoint[:-tau_idx - 1]) \\\n",
    "                / midpoint[:-tau_idx - 1]\n",
    "\n",
    "            # Obtain the self response value\n",
    "            if (trade_sign_no_0_len != 0):\n",
    "                product = log_return_sec * trade_sign_tau\n",
    "                self_response_tau[tau_idx] = np.sum(product)\n",
    "\n",
    "        return (self_response_tau, num)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print('No data')\n",
    "        print(e)\n",
    "        print()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taq_self_response_year_data(ticker, year):\n",
    "    \"\"\"Computes the self response of a year.\n",
    "\n",
    "    Using the taq_self_response_day_data function computes the self-response\n",
    "    function for a year.\n",
    "\n",
    "    :param ticker: string of the abbreviation of stock to be analized\n",
    "     (i.e. 'AAPL').\n",
    "    :param year: string of the year to be analized (i.e '2016').\n",
    "    :return: tuple -- The function returns a tuple with numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    function_name = taq_self_response_year_data.__name__\n",
    "    taq_data_tools_article_reproduction \\\n",
    "        .taq_function_header_print_data(function_name, ticker, ticker, year,\n",
    "                                        '', '')\n",
    "\n",
    "    dates = taq_data_tools_article_reproduction.taq_bussiness_days(year)\n",
    "\n",
    "    self_ = np.zeros(__tau__)\n",
    "    num_s = []\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        try:\n",
    "            data, avg_num = taq_self_response_day_data(ticker, date)\n",
    "            self_ += data\n",
    "            num_s.append(avg_num)\n",
    "\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "    num_s = np.asarray(num_s)\n",
    "    num_s_t = np.sum(num_s, axis=0)\n",
    "\n",
    "    # Saving data\n",
    "    taq_data_tools_article_reproduction \\\n",
    "        .taq_save_data(function_name, self_ / num_s_t, ticker, ticker, year,\n",
    "                       '', '')\n",
    "\n",
    "    return (self_ / num_s_t, num_s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "year = '2008'\n",
    "date = '2008-01-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.6 ms ± 301 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mid_data = taq_midpoint_event_data(ticker, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
